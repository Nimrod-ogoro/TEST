


# ğŸ¤– AI-Powered Q&A Chatbot API (FastAPI + Groq)

An intelligent and lightweight question-answering backend built with **FastAPI** and powered by **Groq's LLaMA 3** models. This API is capable of processing natural language queries and returning accurate, contextual responses â€” ideal for integration into chatbots, educational platforms, support assistants, and more.

Hosted on **[Railway](https://railway.app/)** for rapid deployment and scalability.

---

## ğŸ“Œ Project Overview

This project serves as the backend for an AI-powered Q&A system. It accepts a question from the frontend, processes it using Groq's hosted large language models (like `llama3-70b-8192`), and returns a human-like response.

### âœ… Use Cases

- AI Chatbots
- Customer Support Assistants
- Educational Tutors
- Internal Knowledgebase Search
- Developer Assistants

---

## ğŸš€ Live API Endpoint

```

[https://test-production-d202.up.railway.app/query](https://test-production-d202.up.railway.app/query)

```

Use this endpoint to POST questions and receive AI-generated responses.

---

## ğŸ§  Technology Stack

| Layer        | Tech Used               |
|--------------|-------------------------|
| Language     | Python 3.12+            |
| Web Framework| FastAPI                 |
| AI Provider  | Groq API (LLaMA 3)      |
| Deployment   | Railway                 |
| Environment  | dotenv (.env) support   |

---

## ğŸ“‚ Directory Structure

```

ğŸ“ ai-qa-backend/
â”œâ”€â”€ main.py               # Core FastAPI app
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ .env                  # Environment variables (Groq API key, model)

````

---

## âš™ï¸ Environment Setup

Create a `.env` file with the following values:

```env
GROQ_API_KEY=gsk_xxxxxxxxxxxxxxxxxxxxxx
GROQ_MODEL=llama3-70b-8192
````

Your API key can be obtained from: [https://console.groq.com](https://console.groq.com)

---

## ğŸ“¦ Installation & Local Development

1. **Clone the repo**

   ```bash
   git clone https://github.com/your-username/ai-qa-backend.git
   cd ai-qa-backend
   ```

2. **Create a virtual environment**

   ```bash
   python -m venv venv
   source venv/bin/activate    # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```

4. **Run the development server**

   ```bash
   uvicorn main:app --reload
   ```

   The app will be running at: [http://localhost:8000](http://localhost:8000)

---

## ğŸ” CORS Configuration

For frontend consumption, CORS is pre-enabled for all origins. For production, consider restricting it:

```python
from fastapi.middleware.cors import CORSMiddleware

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Change to your frontend domain
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
```

---

## ğŸ“¤ API Usage

### ğŸ“ Endpoint

```
POST /query
```

### ğŸ”§ Request Body

```json
{
  "question": "What is machine learning?"
}
```

### âœ… Success Response

```json
{
  "answer": "Machine learning is a subset of artificial intelligence (AI)..."
}
```

### âŒ Error Response

```json
{
  "detail": "Failed to process query"
}
```

---

## ğŸŒ Frontend Integration (Example)

Using `fetch` in React or vanilla JavaScript:

```javascript
const fetchAnswer = async (question) => {
  const response = await fetch("https://test-production-d202.up.railway.app/query", {
    method: "POST",
    headers: {
      "Content-Type": "application/json"
    },
    body: JSON.stringify({ question })
  });
  const data = await response.json();
  return data.answer;
};
```

---

## ğŸ“ˆ Deployment (via Railway)

1. Push your code to GitHub
2. Create a project on [Railway](https://railway.app/)
3. Link your GitHub repo
4. Set your environment variables:

   * `GROQ_API_KEY`
   * `GROQ_MODEL`
5. Deploy ğŸš€

---

## ğŸ§¾ `requirements.txt`

```txt
fastapi
uvicorn[standard]
python-dotenv
requests
```

Avoid unused packages like `logging`, `certifi`, or duplicate entries.

---

## ğŸ¤ Contribution

Contributions, bug reports, and feature requests are welcome!

```bash
# Fork this repository
# Create a new branch
git checkout -b feature/your-feature-name

# Commit changes
git commit -m "Add: Your new feature"

# Push and create a PR
```

---

## ğŸ›¡ï¸ License

Licensed under the **MIT License**. See [`LICENSE`](./LICENSE) for more information.

---

## ğŸ‘¨â€ğŸ’» Author

**Nimrod Omanga O.**
Prompt Engineer | Full Stack Developer | AI Systems Architect
[Portfolio](https://portfolio-rouge-zeta-36.vercel.app) Â· [LinkedIn](https://www.linkedin.com/in/nimrodomanga) Â· [GitHub](https://github.com/nimrod-omanga)

---

## ğŸ“¸ Project Preview

```bash
[ğŸ§  Q&A AI Backend]
      â†“
 Frontend App (React, Streamlit, etc.)
      â†“
  POST /query {"question": "Your query"}
      â†“
 Groq LLM API
      â†“
Response â†’ Frontend
```

---

### ğŸ’¬ Questions?

Feel free to open an [issue](https://github.com/your-username/ai-qa-backend/issues) or contact me directly.

---

```

---

### âœ… Next Steps

Would you like me to:
- Export this as a `.md` file?
- Push it directly to your GitHub repo?
- Style a frontend `README.md` to pair with this?
- Add diagrams or badges?

Let me know and Iâ€™ll get it done.
```
